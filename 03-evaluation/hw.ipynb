{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e26b5079",
   "metadata": {},
   "source": [
    "# Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0e5a0c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url_prefix = 'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/03-evaluation/'\n",
    "docs_url = url_prefix + 'search_evaluation/documents-with-ids.json'\n",
    "documents = requests.get(docs_url).json()\n",
    "\n",
    "ground_truth_url = url_prefix + 'search_evaluation/ground-truth-data.csv'\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ac473aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'When does the course begin?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'document': 'c02e79ef'}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "65bc8d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': 'c02e79ef'}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103aff02",
   "metadata": {},
   "source": [
    "# Evaluating retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "18992792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1524e334",
   "metadata": {},
   "source": [
    "# Q1. Minsearch text\n",
    "\n",
    "Now let's evaluate our usual minsearch approach, but tweak the parameters. Let's use the following boosting params:\n",
    "\n",
    "```\n",
    "boost = {'question': 1.5, 'section': 0.1}\n",
    "```\n",
    "What's the hit rate for this approach?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "dad0e61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x7f4cacef46d0>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\", \"id\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36136ab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "279f6286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993f466f87064c78968bfd44294cd98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.848714069591528, 'mrr': 0.7288235717887772}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def minsearch_search(query, course, boost):\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': course},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "metrics = evaluate(ground_truth=ground_truth, search_function=lambda q: minsearch_search(q['question'], q['course'], boost = {'question': 1.5, 'section': 0.1}))\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116fc2c2",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "---\n",
    "The latest version of minsearch also supports vector search. We will use it:\n",
    "\n",
    "\n",
    "```python\n",
    "from minsearch import VectorSearch\n",
    "```\n",
    "\n",
    "We will also use TF-IDF and Singular Value Decomposition to create embeddings from texts. You can refer to our \"Create Your Own Search Engine\" workshop if you want to know more about it.\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "```\n",
    "Let's create embeddings for the \"question\" field:\n",
    "\n",
    "\n",
    "```python\n",
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question']\n",
    "    texts.append(t)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "X = pipeline.fit_transform(texts)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "002dc15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minsearch import VectorSearch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4c29f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_q2  = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question']\n",
    "    texts_q2.append(t)\n",
    "\n",
    "pipeline_q2 = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "X = pipeline_q2.fit_transform(texts_q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893d1699",
   "metadata": {},
   "source": [
    "# Q2. Vector search for question\n",
    "\n",
    "---\n",
    "\n",
    "Now let's index these embeddings with minsearch:\n",
    "\n",
    "\n",
    "```python\n",
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "vindex.fit(X, documents)\n",
    "\n",
    "```\n",
    "Evaluate this seach method. What's MRR for it?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "af7118cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x7f4cfbae3110>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "vindex.fit(X, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5e5916b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608f288157f741b7bddbb5a0f7ac83c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.48173762697212014, 'mrr': 0.3571284489590088}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def search_q2(q):\n",
    "    # 取得查詢向量\n",
    "    query_vec = pipeline_q2.transform([q['question']]) # (1,128)\n",
    "    return vindex.search(\n",
    "        query_vector=query_vec, \n",
    "        filter_dict={'course': q['course']},\n",
    "        num_results=5\n",
    "    )\n",
    "# 執行評估\n",
    "metrics_q2 = evaluate(ground_truth, search_q2)\n",
    "print(metrics_q2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcb5c76",
   "metadata": {},
   "source": [
    "# Q3. Vector search for question and answer\n",
    "\n",
    "---\n",
    "We only used question in Q2. We can use both question and answer:\n",
    "\n",
    "\n",
    "```python\n",
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question'] + ' ' + doc['text']\n",
    "    texts.append(t)\n",
    "```\n",
    "\n",
    "Using the same pipeline (min_df=3 for TF-IDF vectorizer and n_components=128` for SVD), evaluate the performance of this approach\n",
    "\n",
    "What's the hitrate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f71df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_q3  = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question'] + ' ' + doc['text']\n",
    "    texts_q3.append(t)\n",
    "\n",
    "pipeline_q3 = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "X = pipeline_q3.fit_transform(texts_q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57f09623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x7f4dfbba8450>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "vindex.fit(X, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfec7364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023d02d4cdc24527a98b1022cfd31fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.8210503566025502, 'mrr': 0.6717707657949719}\n"
     ]
    }
   ],
   "source": [
    "def search_function(q):\n",
    "    # 取得查詢向量\n",
    "    query_vec = pipeline_q3.transform([q['question']])\n",
    "    return vindex.search(\n",
    "        query_vector=query_vec, \n",
    "        filter_dict={'course': q['course']},\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "# 執行評估\n",
    "metrics = evaluate(ground_truth, search_function)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9a02ce",
   "metadata": {},
   "source": [
    "# Q4. Qdrant\n",
    "---\n",
    "Now let's evaluate the following settings in Qdrant:\n",
    "```\n",
    "text = doc['question'] + ' ' + doc['text']\n",
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "limit = 5\n",
    "```\n",
    "What's the MRR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c799e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed.embedding import TextEmbedding\n",
    "from qdrant_client import QdrantClient, models\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 文字嵌入模型初始化\n",
    "model = TextEmbedding(model_name=\"jinaai/jina-embeddings-v2-small-en\")\n",
    "model_jina = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "# Qdrant 客戶端\n",
    "client = QdrantClient(\"http://localhost:6333\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4c30a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(512,)\n"
     ]
    },
    {
     "ename": "UnexpectedResponse",
     "evalue": "Unexpected Response: 400 (Bad Request)\nRaw response content:\nb'{\"status\":{\"error\":\"Bad request: Empty update request\"},\"time\":0.000032928}'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnexpectedResponse\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[177]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     27\u001b[39m     points.append(\n\u001b[32m     28\u001b[39m         models.PointStruct(\n\u001b[32m     29\u001b[39m             \u001b[38;5;28mid\u001b[39m=doc_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m         )\n\u001b[32m     33\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mlops/lib/python3.11/site-packages/qdrant_client/qdrant_client.py:1633\u001b[39m, in \u001b[36mQdrantClient.upsert\u001b[39m\u001b[34m(self, collection_name, points, wait, ordering, shard_key_selector, **kwargs)\u001b[39m\n\u001b[32m   1626\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1627\u001b[39m         points = \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   1628\u001b[39m             \u001b[38;5;28mself\u001b[39m._embed_models(\n\u001b[32m   1629\u001b[39m                 points, is_query=\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size=\u001b[38;5;28mself\u001b[39m.local_inference_batch_size\n\u001b[32m   1630\u001b[39m             )\n\u001b[32m   1631\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1633\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1634\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1636\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1637\u001b[39m \u001b[43m    \u001b[49m\u001b[43mordering\u001b[49m\u001b[43m=\u001b[49m\u001b[43mordering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1638\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshard_key_selector\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshard_key_selector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1639\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1640\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mlops/lib/python3.11/site-packages/qdrant_client/qdrant_remote.py:1911\u001b[39m, in \u001b[36mQdrantRemote.upsert\u001b[39m\u001b[34m(self, collection_name, points, wait, ordering, shard_key_selector, **kwargs)\u001b[39m\n\u001b[32m   1908\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(points, models.Batch):\n\u001b[32m   1909\u001b[39m     points = models.PointsBatch(batch=points, shard_key=shard_key_selector)\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m http_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopenapi_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoints_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert_points\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1913\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1914\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpoint_insert_operations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mordering\u001b[49m\u001b[43m=\u001b[49m\u001b[43mordering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1916\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.result\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m http_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mUpsert returned None result\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1918\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m http_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mlops/lib/python3.11/site-packages/qdrant_client/http/api/points_api.py:987\u001b[39m, in \u001b[36mSyncPointsApi.upsert_points\u001b[39m\u001b[34m(self, collection_name, wait, ordering, point_insert_operations)\u001b[39m\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupsert_points\u001b[39m(\n\u001b[32m    978\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    979\u001b[39m     collection_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    982\u001b[39m     point_insert_operations: m.PointInsertOperations = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    983\u001b[39m ) -> m.InlineResponse2006:\n\u001b[32m    984\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[33;03m    Perform insert + updates on points. If point with given ID already exists - it will be overwritten.\u001b[39;00m\n\u001b[32m    986\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m987\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_for_upsert_points\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[43m        \u001b[49m\u001b[43mordering\u001b[49m\u001b[43m=\u001b[49m\u001b[43mordering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    991\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpoint_insert_operations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoint_insert_operations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mlops/lib/python3.11/site-packages/qdrant_client/http/api/points_api.py:512\u001b[39m, in \u001b[36m_PointsApi._build_for_upsert_points\u001b[39m\u001b[34m(self, collection_name, wait, ordering, point_insert_operations)\u001b[39m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m headers:\n\u001b[32m    511\u001b[39m     headers[\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m512\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m=\u001b[49m\u001b[43mm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInlineResponse2006\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPUT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/collections/\u001b[39;49m\u001b[38;5;132;43;01m{collection_name}\u001b[39;49;00m\u001b[33;43m/points\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mlops/lib/python3.11/site-packages/qdrant_client/http/api_client.py:95\u001b[39m, in \u001b[36mApiClient.request\u001b[39m\u001b[34m(self, type_, method, url, path_params, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mint\u001b[39m(kwargs[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     94\u001b[39m request = \u001b[38;5;28mself\u001b[39m._client.build_request(method, url, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mlops/lib/python3.11/site-packages/qdrant_client/http/api_client.py:130\u001b[39m, in \u001b[36mApiClient.send\u001b[39m\u001b[34m(self, request, type_)\u001b[39m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    129\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ResponseHandlingException(e)\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedResponse.for_response(response)\n",
      "\u001b[31mUnexpectedResponse\u001b[39m: Unexpected Response: 400 (Bad Request)\nRaw response content:\nb'{\"status\":{\"error\":\"Bad request: Empty update request\"},\"time\":0.000032928}'"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "collection_name = \"q4_evaluation\"\n",
    "\n",
    "client.delete_collection(collection_name=collection_name)\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(size=512, distance=models.Distance.COSINE),\n",
    ")\n",
    "\n",
    "\n",
    "import uuid\n",
    "\n",
    "# 建立向量並上傳\n",
    "points = []\n",
    "for idx, doc in tqdm(enumerate(documents)):\n",
    "    \n",
    "\n",
    "    full_text = doc[\"question\"] + \" \" + doc[\"text\"]\n",
    "\n",
    "    points.append(\n",
    "        models.PointStruct(\n",
    "            id=idx,\n",
    "            vector=models.Document(text=full_text, model=model_jina),\n",
    "            payload={\"document\": doc[\"id\"], \"question\": doc[\"question\"], \"text\": doc[\"text\"]},\n",
    "        )\n",
    "    )\n",
    "\n",
    "client.upsert(collection_name=collection_name, points=points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "39be1fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2038e9383f4e63b81c3cb33ce727ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'When does the course begin?', 'course': 'data-engineering-zoomcamp', 'document': 'c02e79ef'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mDeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\u001b[0m \u001b[1;30m(raised from /tmp/ipykernel_218023/2751943783.py:7)\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'ScoredPoint' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[173]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      5\u001b[39m     query_vector = \u001b[38;5;28mlist\u001b[39m(model.embed([full_text]))[\u001b[32m0\u001b[39m]\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m client.search(\n\u001b[32m      8\u001b[39m         collection_name=collection_name,\n\u001b[32m      9\u001b[39m         query_vector=query_vector,\n\u001b[32m     10\u001b[39m         limit=limit,\n\u001b[32m     11\u001b[39m         with_payload=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     12\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m metrics_q4 = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_q4\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(metrics_q4)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[155]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(ground_truth, search_function)\u001b[39m\n\u001b[32m     26\u001b[39m     doc_id = q[\u001b[33m'\u001b[39m\u001b[33mdocument\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     27\u001b[39m     results = search_function(q)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     relevance = \u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     29\u001b[39m     relevance_total.append(relevance)\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     32\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhit_rate\u001b[39m\u001b[33m'\u001b[39m: hit_rate(relevance_total),\n\u001b[32m     33\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmrr\u001b[39m\u001b[33m'\u001b[39m: mrr(relevance_total),\n\u001b[32m     34\u001b[39m }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[155]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     26\u001b[39m     doc_id = q[\u001b[33m'\u001b[39m\u001b[33mdocument\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     27\u001b[39m     results = search_function(q)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     relevance = [\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m == doc_id \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[32m     29\u001b[39m     relevance_total.append(relevance)\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     32\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhit_rate\u001b[39m\u001b[33m'\u001b[39m: hit_rate(relevance_total),\n\u001b[32m     33\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmrr\u001b[39m\u001b[33m'\u001b[39m: mrr(relevance_total),\n\u001b[32m     34\u001b[39m }\n",
      "\u001b[31mTypeError\u001b[39m: 'ScoredPoint' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def search_q4(q, limit: int = 5):\n",
    "    print(q)\n",
    "    # query_text = q['question']\n",
    "    full_text = doc[\"question\"] + \" \" + doc[\"text\"]\n",
    "    query_vector = list(model.embed([full_text]))[0]\n",
    "    \n",
    "    return client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_vector,\n",
    "        limit=limit,\n",
    "        with_payload=True\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "metrics_q4 = evaluate(ground_truth, search_q4)\n",
    "print(metrics_q4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3dea0e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a4e37739a64af0bdf27cc8e7f820f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[136]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_q4\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[133]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(ground_truth, search_function)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m tqdm(ground_truth):\n\u001b[32m     26\u001b[39m     doc_id = q[\u001b[33m'\u001b[39m\u001b[33mdocument\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     results = \u001b[43msearch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     relevance = [d[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m] == doc_id \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[32m     29\u001b[39m     relevance_total.append(relevance)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[135]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36msearch_q4\u001b[39m\u001b[34m(query, limit)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msearch_q4\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m, limit: \u001b[38;5;28mint\u001b[39m = \u001b[32m5\u001b[39m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m client.search(\n\u001b[32m      3\u001b[39m         collection_name=collection_name,\n\u001b[32m      4\u001b[39m         \u001b[38;5;66;03m# query_vector=model.embed([query])[0],\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m         query_vector = \u001b[38;5;28mlist\u001b[39m(model.embed([query]))[\u001b[32m0\u001b[39m],\n\u001b[32m      6\u001b[39m         limit=limit,\n\u001b[32m      7\u001b[39m         with_payload=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      8\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mlops/lib/python3.11/site-packages/fastembed/text/text_embedding.py:187\u001b[39m, in \u001b[36mTextEmbedding.embed\u001b[39m\u001b[34m(self, documents, batch_size, parallel, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed\u001b[39m(\n\u001b[32m    166\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    167\u001b[39m     documents: Union[\u001b[38;5;28mstr\u001b[39m, Iterable[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[32m   (...)\u001b[39m\u001b[32m    170\u001b[39m     **kwargs: Any,\n\u001b[32m    171\u001b[39m ) -> Iterable[NumpyArray]:\n\u001b[32m    172\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[33;03m    Encode a list of documents into list of embeddings.\u001b[39;00m\n\u001b[32m    174\u001b[39m \u001b[33;03m    We use mean pooling with attention so that the model can handle variable-length inputs.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    185\u001b[39m \u001b[33;03m        List of embeddings, one per document\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.embed(documents, batch_size, parallel, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mlops/lib/python3.11/site-packages/fastembed/text/onnx_embedding.py:283\u001b[39m, in \u001b[36mOnnxTextEmbedding.embed\u001b[39m\u001b[34m(self, documents, batch_size, parallel, **kwargs)\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed\u001b[39m(\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    263\u001b[39m     documents: Union[\u001b[38;5;28mstr\u001b[39m, Iterable[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[32m   (...)\u001b[39m\u001b[32m    266\u001b[39m     **kwargs: Any,\n\u001b[32m    267\u001b[39m ) -> Iterable[NumpyArray]:\n\u001b[32m    268\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    269\u001b[39m \u001b[33;03m    Encode a list of documents into list of embeddings.\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[33;03m    We use mean pooling with attention so that the model can handle variable-length inputs.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    281\u001b[39m \u001b[33;03m        List of embeddings, one per document\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embed_documents(\n\u001b[32m    284\u001b[39m         model_name=\u001b[38;5;28mself\u001b[39m.model_name,\n\u001b[32m    285\u001b[39m         cache_dir=\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.cache_dir),\n\u001b[32m    286\u001b[39m         documents=documents,\n\u001b[32m    287\u001b[39m         batch_size=batch_size,\n\u001b[32m    288\u001b[39m         parallel=parallel,\n\u001b[32m    289\u001b[39m         providers=\u001b[38;5;28mself\u001b[39m.providers,\n\u001b[32m    290\u001b[39m         cuda=\u001b[38;5;28mself\u001b[39m.cuda,\n\u001b[32m    291\u001b[39m         device_ids=\u001b[38;5;28mself\u001b[39m.device_ids,\n\u001b[32m    292\u001b[39m         local_files_only=\u001b[38;5;28mself\u001b[39m._local_files_only,\n\u001b[32m    293\u001b[39m         specific_model_path=\u001b[38;5;28mself\u001b[39m._specific_model_path,\n\u001b[32m    294\u001b[39m         **kwargs,\n\u001b[32m    295\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mlops/lib/python3.11/site-packages/fastembed/text/onnx_text_model.py:130\u001b[39m, in \u001b[36mOnnxTextModel._embed_documents\u001b[39m\u001b[34m(self, model_name, cache_dir, documents, batch_size, parallel, providers, cuda, device_ids, local_files_only, specific_model_path, **kwargs)\u001b[39m\n\u001b[32m    127\u001b[39m         \u001b[38;5;28mself\u001b[39m.load_onnx_model()\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iter_batch(documents, batch_size):\n\u001b[32m    129\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post_process_onnx_output(\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43monnx_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, **kwargs\n\u001b[32m    131\u001b[39m         )\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m parallel == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mlops/lib/python3.11/site-packages/fastembed/text/onnx_text_model.py:79\u001b[39m, in \u001b[36mOnnxTextModel.onnx_embed\u001b[39m\u001b[34m(self, documents, **kwargs)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34monnx_embed\u001b[39m(\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     76\u001b[39m     documents: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m     77\u001b[39m     **kwargs: Any,\n\u001b[32m     78\u001b[39m ) -> OnnxOutputContext:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     encoded = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     input_ids = np.array([e.ids \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m encoded])\n\u001b[32m     81\u001b[39m     attention_mask = np.array([e.attention_mask \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m encoded])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mlops/lib/python3.11/site-packages/fastembed/text/onnx_text_model.py:72\u001b[39m, in \u001b[36mOnnxTextModel.tokenize\u001b[39m\u001b[34m(self, documents, **kwargs)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, documents: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], **kwargs: Any) -> \u001b[38;5;28mlist\u001b[39m[Encoding]:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]"
     ]
    }
   ],
   "source": [
    "evaluate(ground_truth, search_q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be857d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c212fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
