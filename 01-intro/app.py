import streamlit as st
# from elasticsearch import Elasticsearch
from elasticsearch.exceptions import NotFoundError
from elasticsearch.helpers import bulk
import requests
import json
import os
from tqdm.auto import tqdm
from llm import build_prompt, llm
from es import elastic_index, elastic_search
from fetch_data import fetch_documents
import tiktoken



# @st.cache_data


# -------------------- Streamlit UI --------------------

st.set_page_config(page_title="Course FAQ Search", layout="wide")
st.title("ğŸ“š Course QA Search with Elasticsearch")

with st.sidebar:
    st.header("è¨­å®š")
    if st.button("é‡æ–°å»ºç«‹ç´¢å¼•"):
        docs = fetch_documents()
        elastic_index(docs)
        st.success("é‡æ–°ç´¢å¼•å®Œæˆ âœ…")
        
        
    st.header("æœå°‹æ¬„ä½èˆ‡æ¬Šé‡è¨­å®š")

    use_question = st.checkbox("ä½¿ç”¨ question æ¬„ä½", value=True)
    boost_question = st.number_input("question æ¬Šé‡", value=4, min_value=1) if use_question else 0

    use_text = st.checkbox("ä½¿ç”¨ text æ¬„ä½", value=True)
    boost_text = st.number_input("text æ¬„ä½æ¬Šé‡", value=1, min_value=1) if use_text else 0

    use_section = st.checkbox("ä½¿ç”¨ section æ¬„ä½", value=False)
    boost_section = st.number_input("section æ¬Šé‡", value=1, min_value=1) if use_section else 0

    search_fields = {}
    if use_question:
        search_fields["question"] = boost_question
    if use_text:
        search_fields["text"] = boost_text
    if use_section:
        search_fields["section"] = boost_section
    
    st.header("èª²ç¨‹ç¯©é¸")
    course_filter = st.selectbox(
        "é¸æ“‡è¦ç¯©é¸çš„èª²ç¨‹ï¼ˆå¯é¸ï¼‰",
        ["ä¸éæ¿¾", "data-engineering-zoomcamp", "mlops-zoomcamp", "machine-learning-zoomcamp"]
    )

    


st.markdown("è«‹è¼¸å…¥ä½ çš„å•é¡Œé—œéµå­—ï¼š")

query = st.text_input("Query", value="how do I run kafka?")

# æ¬„ä½æ¬Šé‡è¨­å®šï¼ˆå›ºå®šä½†å¯æ”¹ç‚ºå‹•æ…‹ï¼‰


if query:
    with st.spinner("æœå°‹ä¸­..."):
        print(search_fields)
        hits = elastic_search(query, "course-questions", search_fields, 5, course_filter)
        
    print(f"hits: {hits}")
    if hits:
        top_score = hits[0]['_score']
        print(top_score)
        st.markdown(f"### ğŸ” Top Result Score: `{top_score:.2f}`\n")

        for i, hit in enumerate(hits, 1):
            st.subheader(f"ğŸ“„ çµæœ {i} â€” Score: {hit['_score']:.2f}")
            st.markdown(f"**Section:** {hit['section']}")
            st.markdown(f"**Question:** {hit['question']}")
            st.markdown(f"**Answer:** {hit['text']}")
            st.markdown("---")
            
        
    else:
        st.warning("æŸ¥ç„¡çµæœ")


    prompt = build_prompt(query, hits)
    print(f"Prompt: {prompt}")
    print(f"Length of prompt: {len(prompt)}")
    
    enc = tiktoken.encoding_for_model("gpt-4o")
    tokens = enc.encode(prompt)
    print(f"Token æ•¸é‡: {len(tokens)}")


    answer = llm(prompt)
    print(f"Answer: {answer}")