{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae8e2ae0-da25-44e7-ae82-024173150a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57de60e5-b96c-499c-a7cf-0f30fc33b324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - Can I still join the course after the start date?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca4f864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting minsearch\n",
      "  Downloading minsearch-0.0.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pandas in /Users/chenyuan/anaconda3/envs/llm/lib/python3.11/site-packages (from minsearch) (2.3.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/chenyuan/anaconda3/envs/llm/lib/python3.11/site-packages (from minsearch) (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/chenyuan/anaconda3/envs/llm/lib/python3.11/site-packages (from pandas->minsearch) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/chenyuan/anaconda3/envs/llm/lib/python3.11/site-packages (from pandas->minsearch) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/chenyuan/anaconda3/envs/llm/lib/python3.11/site-packages (from pandas->minsearch) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/chenyuan/anaconda3/envs/llm/lib/python3.11/site-packages (from pandas->minsearch) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/chenyuan/anaconda3/envs/llm/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->minsearch) (1.17.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/chenyuan/anaconda3/envs/llm/lib/python3.11/site-packages (from scikit-learn->minsearch) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/chenyuan/anaconda3/envs/llm/lib/python3.11/site-packages (from scikit-learn->minsearch) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/chenyuan/anaconda3/envs/llm/lib/python3.11/site-packages (from scikit-learn->minsearch) (3.6.0)\n",
      "Downloading minsearch-0.0.3-py3-none-any.whl (9.3 kB)\n",
      "Installing collected packages: minsearch\n",
      "Successfully installed minsearch-0.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce7d0d18-5c07-4010-9f90-bbd021f110c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x11245f150>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa755a08-b98d-4e92-8994-04e6108499d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "# openai_client = OpenAI()\n",
    "\n",
    "openai_client = OpenAI(\n",
    "        base_url=\"https://openrouter.ai/api/v1\",\n",
    "        api_key=os.getenv(\"OPENROUTER_API_KEY\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b21237c3-80e9-429c-a089-d45428087046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cc5784e-6515-42e5-be62-8fb915df1088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97d35dec-c25f-472d-b961-20d5c30902ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8602f40b-ad3b-49c9-b3cc-051a79c888bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fd4497b-c5d5-4258-b950-6b35d1af4ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To run Kafka, you can execute the following command in your project directory for the Java Kafka producer:\\n\\n```\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\\n```\\n\\nFor Python, ensure you create a virtual environment and install the necessary dependencies. You can create the environment and install packages with these commands:\\n\\n1. Create a virtual environment:\\n   ```\\n   python -m venv env\\n   ```\\n\\n2. Activate the virtual environment:\\n   - On MacOS/Linux:\\n     ```\\n     source env/bin/activate\\n     ```\\n   - On Windows:\\n     ```\\n     env\\\\Scripts\\\\activate\\n     ```\\n\\n3. Install the required packages from `requirements.txt`:\\n   ```\\n   pip install -r ../requirements.txt\\n   ```\\n\\nMake sure to run the activation command every time you need to use the virtual environment, and deactivate it with `deactivate` when done.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('how do I run kafka?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "385b012f-4905-422d-8d7c-3d542dfe5a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, you can still enroll in the course even after it has started. You are eligible to submit homework assignments, but be aware that there will be deadlines for the final project, so it's advisable not to leave everything to the last minute.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('the course has already started, can I still enroll?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71154c38-cc68-4d29-9809-f0f0545c79c3",
   "metadata": {},
   "source": [
    "## RAG with Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a78f5cb1-709c-4b48-a9b9-1738b75415de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenyuan/anaconda3/envs/llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61784d3a-b8f1-45b2-9404-e3495dca1152",
   "metadata": {},
   "outputs": [],
   "source": [
    "qd_client = QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f435b8da-834e-45c1-b83e-e28c294c044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4fa85d4-af1d-46b9-a281-87c5f332bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"zoomcamp-faq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fce5957c-22c2-43e6-8dc1-af0c1acc884e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.delete_collection(collection_name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "722e75a1-95ab-4388-94c0-800ec4f58866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb29d2a0-64df-4ea2-8920-8e6a16c4bcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=1, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1348ef23-364a-4719-94fe-7a9cf8ea8371",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    text = doc['question'] + ' ' + doc['text']\n",
    "    vector = models.Document(text=text, model=model_handle)\n",
    "    point = models.PointStruct(\n",
    "        id=i,\n",
    "        vector=vector,\n",
    "        payload=doc\n",
    "    )\n",
    "    points.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5e0e480-2af4-4a0e-b3d0-28a1e2181195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=2, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c9be7f7-2813-432b-8d73-3dff448dd02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'I just discovered the course. Can I still join it?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6698670a-6fe7-4f51-83f7-281e80e06f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(question):\n",
    "    print('vector_search is used')\n",
    "    \n",
    "    course = 'data-engineering-zoomcamp'\n",
    "    query_points = qd_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(\n",
    "            text=question,\n",
    "            model=model_handle \n",
    "        ),\n",
    "        query_filter=models.Filter( \n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"course\",\n",
    "                    match=models.MatchValue(value=course)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=5,\n",
    "        with_payload=True\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for point in query_points.points:\n",
    "        results.append(point.payload)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d80d18e3-c512-4f97-9f77-b1145fdb73bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = vector_search(query)\n",
    "    print(search_results)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90bdc6f4-b6f8-4491-84f4-bbd8a6b9f6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_search is used\n",
      "[{'text': 'In the project directory, run:\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: How to run producer/consumer/kstreams/etc in terminal', 'course': 'data-engineering-zoomcamp'}, {'text': 'For example, when running JsonConsumer.java, got:\\nConsuming form kafka started\\nRESULTS:::0\\nRESULTS:::0\\nRESULTS:::0\\nOr when running JsonProducer.java, got:\\nException in thread \"main\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\nSolution:\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent', 'course': 'data-engineering-zoomcamp'}, {'text': 'If you have this error, it most likely that your kafka broker docker container is not working.\\nUse docker ps to confirm\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.', 'section': 'Module 6: streaming with kafka', 'question': 'kafka.errors.NoBrokersAvailable: NoBrokersAvailable', 'course': 'data-engineering-zoomcamp'}, {'text': \"Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\\nTo create a virtual env and install packages (run only once)\\npython -m venv env\\nsource env/bin/activate\\npip install -r ../requirements.txt\\nTo activate it (you'll need to run it every time you need the virtual env):\\nsource env/bin/activate\\nTo deactivate it:\\ndeactivate\\nThis works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\\nAlso the virtual environment should be created only to run the python file. Docker images should first all be up and running.\", 'section': 'Module 6: streaming with kafka', 'question': 'Module “kafka” not found when trying to run producer.py', 'course': 'data-engineering-zoomcamp'}, {'text': \"Below I have listed some steps I took to rectify this and potentially other minor errors, in Windows:\\nUse the git bash terminal in windows.\\nActivate python venv from git bash: source .venv/Scripts/activate\\nModify the seed_kafka.py file: in the first line, replace python3 with python.\\nNow from git bash, run the seed-kafka cmd. It should work now.\\nAdditional Notes:\\nYou can connect to the RisingWave cluster from Powershell with the command psql -h localhost -p 4566 -d dev -U root , otherwise it asks for a password.\\nThe equivalent of source commands.sh  in Powershell is . .\\\\commands.sh from the workshop directory.\\nHope this can save you from some trouble in case you're doing this workshop on Windows like I am.\\n—--------------------------------------------------------------------------------------\", 'section': 'Workshop 2 - RisingWave', 'question': 'Psycopg2 InternalError: Failed to run the query - when running the seed-kafka command after initial setup.', 'course': 'data-engineering-zoomcamp'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"To run Kafka, you can follow these steps based on your context:\\n\\n1. **Ensure your Kafka broker is running**: Check if your Kafka broker Docker container is working by running `docker ps`. If it's not running, navigate to the folder with your Docker Compose YAML file and execute `docker compose up -d` to start all instances.\\n\\n2. **Run the producer or consumer**:\\n   - For Java Kafka applications, go to your project directory and run the following command, replacing `<jar_name>` with the actual name of your JAR file:\\n     ```\\n     java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\\n     ```\\n   - Ensure that your `StreamsConfig.BOOTSTRAP_SERVERS_CONFIG` in your Java scripts points to the correct Kafka server URL. Additionally, confirm that `KAFKA_CLUSTER_KEY` and `KAFKA_CLUSTER_SECRET` in your `Secrets.java` are updated correctly.\\n\\nBy following these steps, you should be able to run Kafka successfully.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('how do I run kafka?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "886901ee-6e55-4295-a106-af25e6483da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'In the project directory, run:\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Java Kafka: How to run producer/consumer/kstreams/etc in terminal',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'For example, when running JsonConsumer.java, got:\\nConsuming form kafka started\\nRESULTS:::0\\nRESULTS:::0\\nRESULTS:::0\\nOr when running JsonProducer.java, got:\\nException in thread \"main\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\nSolution:\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'If you have this error, it most likely that your kafka broker docker container is not working.\\nUse docker ps to confirm\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'kafka.errors.NoBrokersAvailable: NoBrokersAvailable',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\\nTo create a virtual env and install packages (run only once)\\npython -m venv env\\nsource env/bin/activate\\npip install -r ../requirements.txt\\nTo activate it (you'll need to run it every time you need the virtual env):\\nsource env/bin/activate\\nTo deactivate it:\\ndeactivate\\nThis works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\\nAlso the virtual environment should be created only to run the python file. Docker images should first all be up and running.\",\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Module “kafka” not found when trying to run producer.py',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Below I have listed some steps I took to rectify this and potentially other minor errors, in Windows:\\nUse the git bash terminal in windows.\\nActivate python venv from git bash: source .venv/Scripts/activate\\nModify the seed_kafka.py file: in the first line, replace python3 with python.\\nNow from git bash, run the seed-kafka cmd. It should work now.\\nAdditional Notes:\\nYou can connect to the RisingWave cluster from Powershell with the command psql -h localhost -p 4566 -d dev -U root , otherwise it asks for a password.\\nThe equivalent of source commands.sh  in Powershell is . .\\\\commands.sh from the workshop directory.\\nHope this can save you from some trouble in case you're doing this workshop on Windows like I am.\\n—--------------------------------------------------------------------------------------\",\n",
       "  'section': 'Workshop 2 - RisingWave',\n",
       "  'question': 'Psycopg2 InternalError: Failed to run the query - when running the seed-kafka command after initial setup.',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[{'text': 'In the project directory, run:\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: How to run producer/consumer/kstreams/etc in terminal', 'course': 'data-engineering-zoomcamp'}, {'text': 'For example, when running JsonConsumer.java, got:\\nConsuming form kafka started\\nRESULTS:::0\\nRESULTS:::0\\nRESULTS:::0\\nOr when running JsonProducer.java, got:\\nException in thread \"main\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\nSolution:\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)', 'section': 'Module 6: streaming with kafka', 'question': 'Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent', 'course': 'data-engineering-zoomcamp'}, {'text': 'If you have this error, it most likely that your kafka broker docker container is not working.\\nUse docker ps to confirm\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.', 'section': 'Module 6: streaming with kafka', 'question': 'kafka.errors.NoBrokersAvailable: NoBrokersAvailable', 'course': 'data-engineering-zoomcamp'}, {'text': \"Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\\nTo create a virtual env and install packages (run only once)\\npython -m venv env\\nsource env/bin/activate\\npip install -r ../requirements.txt\\nTo activate it (you'll need to run it every time you need the virtual env):\\nsource env/bin/activate\\nTo deactivate it:\\ndeactivate\\nThis works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\\nAlso the virtual environment should be created only to run the python file. Docker images should first all be up and running.\", 'section': 'Module 6: streaming with kafka', 'question': 'Module “kafka” not found when trying to run producer.py', 'course': 'data-engineering-zoomcamp'}, {'text': \"Below I have listed some steps I took to rectify this and potentially other minor errors, in Windows:\\nUse the git bash terminal in windows.\\nActivate python venv from git bash: source .venv/Scripts/activate\\nModify the seed_kafka.py file: in the first line, replace python3 with python.\\nNow from git bash, run the seed-kafka cmd. It should work now.\\nAdditional Notes:\\nYou can connect to the RisingWave cluster from Powershell with the command psql -h localhost -p 4566 -d dev -U root , otherwise it asks for a password.\\nThe equivalent of source commands.sh  in Powershell is . .\\\\commands.sh from the workshop directory.\\nHope this can save you from some trouble in case you're doing this workshop on Windows like I am.\\n—--------------------------------------------------------------------------------------\", 'section': 'Workshop 2 - RisingWave', 'question': 'Psycopg2 InternalError: Failed to run the query - when running the seed-kafka command after initial setup.', 'course': 'data-engineering-zoomcamp'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4b101c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4afef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
