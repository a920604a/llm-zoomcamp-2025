{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c36ed41c-fbb9-4e99-a583-46e5898ac9e4",
   "metadata": {},
   "source": [
    "Follow along this tutorial: https://github.com/alexeygrigorev/rag-agents-workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f2c47-4552-4620-bc04-c484617aa597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: minsearch in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (0.0.3)\n",
      "Requirement already satisfied: pandas in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from minsearch) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from minsearch) (1.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from pandas->minsearch) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from pandas->minsearch) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from pandas->minsearch) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from pandas->minsearch) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->minsearch) (1.17.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from scikit-learn->minsearch) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from scikit-learn->minsearch) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from scikit-learn->minsearch) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f94620-4db6-4154-915c-cce211e5b305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e29ed14f-af3a-4340-8f40-1c7c2cc207c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x7f75dcb0eaf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minsearch import AppendableIndex\n",
    "\n",
    "index = AppendableIndex(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8749d06-f715-4ab5-ac29-9f35bee27352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de65e06c-8fb5-4bf8-b24e-09661ed36d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Can I still join the course?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa4be2c8-2f4e-4590-aef2-01220a82c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f8aa058-c45e-42b4-997e-40c8aa384b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = search(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac1f8d40-a251-4fbf-b210-f602df8def75",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_prompt(question, search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17a0317c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # 會讀取當前目錄下 .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c45d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b029b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from google import genai\n",
    "\n",
    "def llm(prompt):\n",
    "  client = genai.Client()\n",
    "\n",
    "  response = client.models.generate_content(\n",
    "      model=\"gemini-2.5-flash\", contents=prompt\n",
    "  )\n",
    "  return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "377e1607-5dfc-422d-af86-2179e3e4e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3be8f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but the provided FAQ context does not contain any information about how to patch KDE under FreeBSD.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"How do I patch KDE under FreeBSD?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee43fa1-ce00-4598-9b21-2c8a17d65c09",
   "metadata": {},
   "source": [
    "## \"Agentic\" RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cc51b91-5779-43b2-80c6-c7159afbb486",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "At the beginning the context is EMPTY.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "If CONTEXT is EMPTY, you can use our FAQ database.\n",
    "In this case, use the following output template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\"\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cae701f4-342a-41fd-9ab6-46e3eceff7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Can I still join the course?'\n",
    "context = 'EMPTY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f64b066f-3f6a-4a7a-aeab-bda815dcacdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08d87856-489e-4a8b-8818-271d0da83188",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_json = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a844770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"The student is asking about course enrollment, specifically if they can still join. This is a common question related to course administration and enrollment deadlines, which is very likely to be addressed in an FAQ database.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "350ac019-50cf-48a2-b47b-05fa13cf6ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "247bd647-f385-4ab7-84e7-4bf231c99021",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = json.loads(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "258864cf-0fff-46cc-9436-227b4c918b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEARCH'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe7e614a-42b3-4c81-9940-8eae90193e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    return context.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9658330f-cfd4-4400-9d73-dc149dc1672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = search(question)\n",
    "context = build_context(search_results)\n",
    "prompt = prompt_template.format(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71737247-862f-48f9-a59c-a5f1d5ef575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_json = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "907c7992-6dad-431e-8cec-3407d3a38f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"Yes, you can still join the course. Even if you haven't registered, you are eligible to submit the homeworks. You can just start learning and submitting homework without formal registration, as it's not checked against any registered list. However, be mindful of deadlines for final projects.\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(answer_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dbdbca-ebde-4dc4-8b4a-11d93232516f",
   "metadata": {},
   "source": [
    "## Agentic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53c272d4-d5a8-4e3f-9484-c3a5ffa4db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedup(seq):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for el in seq:\n",
    "        _id = el['_id']\n",
    "        if _id in seen:\n",
    "            continue\n",
    "        seen.add(_id)\n",
    "        result.append(el)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aff2fbf0-9800-4d24-a5e7-083482657720",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "\n",
    "The CONTEXT is build with the documents from our FAQ database.\n",
    "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
    "from FAQ to and add them to the context.\n",
    "PREVIOUS_ACTIONS contains the actions you already performed.\n",
    "\n",
    "At the beginning the CONTEXT is empty.\n",
    "\n",
    "You can perform the following actions:\n",
    "\n",
    "- Search in the FAQ database to get more data for the CONTEXT\n",
    "- Answer the question using the CONTEXT\n",
    "- Answer the question using your own knowledge\n",
    "\n",
    "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
    "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
    "\n",
    "Don't use search queries used at the previous iterations.\n",
    "\n",
    "Don't repeat previously performed actions.\n",
    "\n",
    "Don't perform more than {max_iterations} iterations for a given student question.\n",
    "The current iteration number: {iteration_number}. If we exceed the allowed number \n",
    "of iterations, give the best possible answer with the provided information.\n",
    "\n",
    "Output templates:\n",
    "\n",
    "If you want to perform search, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\",\n",
    "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER_CONTEXT\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<SEARCH_QUERIES>\n",
    "{search_queries}\n",
    "</SEARCH_QUERIES>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "<PREVIOUS_ACTIONS>\n",
    "{previous_actions}\n",
    "</PREVIOUS_ACTIONS>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "210e426c-8135-4d13-bfe9-b60e21346ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'how do I do well on module 1'\n",
    "max_iterations = 3\n",
    "iteration_number = 0\n",
    "search_queries = []\n",
    "search_results  = []\n",
    "previous_actions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "67aee99b-850f-4ced-82e0-07f365284798",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=max_iterations,\n",
    "    iteration_number=iteration_number\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "329d87ee-3262-4f49-9760-7ecb3c931c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_json = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2c162430-5f56-40fd-9b8c-e95a31cc572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = json.loads(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "406e6100-a9ff-4871-889f-aaafda644f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_actions.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd9e3965-8260-4394-a1f3-e8c8e9785e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = answer['keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "309ed6f7-bf4e-494f-9ff1-ffcae5d9b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for kw in keywords:\n",
    "    search_queries.append(kw)\n",
    "    sr = search(kw)\n",
    "    search_results.extend(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6edcdb00-5a54-4bbe-af72-e837c37d091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = dedup(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a84cf11d-6673-474a-b3fc-efadae0f067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_number = 2\n",
    "\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=max_iterations,\n",
    "    iteration_number=iteration_number\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "487c3127-5954-4b19-83d1-795f0c0c1525",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_json = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f770a0aa-b057-4197-92f5-2f1f4d33dbbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'answer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43manswer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manswer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'answer'"
     ]
    }
   ],
   "source": [
    "print(answer['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "46b985cc-1b98-4522-aeaf-56e6f2beaab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"The student is asking about success in Module 1. Since the CONTEXT is currently empty, I need to search the FAQ database for information related to Module 1, success tips, and what's required for it.\",\n",
      "  \"keywords\": [\n",
      "    \"Module 1 success tips\",\n",
      "    \"how to succeed in Module 1\",\n",
      "    \"Module 1 requirements\",\n",
      "    \"Module 1 study guide\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #1...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "Module 1 success tips\n",
      "Module 1 requirements\n",
      "how to succeed in Module 1\n",
      "Module 1 study guide\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Module “kafka” not found when trying to run producer.py\n",
      "answer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\n",
      "To create a virtual env and install packages (run only once)\n",
      "python -m venv env\n",
      "source env/bin/activate\n",
      "pip install -r ../requirements.txt\n",
      "To activate it (you'll need to run it every time you need the virtual env):\n",
      "source env/bin/activate\n",
      "To deactivate it:\n",
      "deactivate\n",
      "This works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\n",
      "Also the virtual environment should be created only to run the python file. Docker images should first all be up and running.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The student is asking about success in Module 1. Since the CONTEXT is currently empty, I need to search the FAQ database for information related to Module 1, success tips, and what's required for it.\", \"keywords\": [\"Module 1 success tips\", \"how to succeed in Module 1\", \"Module 1 requirements\", \"Module 1 study guide\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"The student is asking for general success tips for Module 1. The current CONTEXT primarily contains solutions to specific technical errors within Module 1 (Docker and Terraform, Python, SQLAlchemy, Psycopg2 issues). While resolving these issues is part of success, the context doesn't provide broader guidance on 'what to do to be successful'. I need to search for more conceptual information about Module 1, such as its objectives, key topics, or learning outcomes, which can indirectly inform the student on how to succeed.\",\n",
      "  \"keywords\": [\n",
      "    \"Module 1 learning outcomes\",\n",
      "    \"Module 1 core topics\",\n",
      "    \"Module 1 objectives\",\n",
      "    \"Module 1 important skills\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #2...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "Module 1 study guide\n",
      "Module 1 requirements\n",
      "Module 1 important skills\n",
      "how to succeed in Module 1\n",
      "Module 1 learning outcomes\n",
      "Module 1 core topics\n",
      "Module 1 success tips\n",
      "Module 1 objectives\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Module “kafka” not found when trying to run producer.py\n",
      "answer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\n",
      "To create a virtual env and install packages (run only once)\n",
      "python -m venv env\n",
      "source env/bin/activate\n",
      "pip install -r ../requirements.txt\n",
      "To activate it (you'll need to run it every time you need the virtual env):\n",
      "source env/bin/activate\n",
      "To deactivate it:\n",
      "deactivate\n",
      "This works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\n",
      "Also the virtual environment should be created only to run the python file. Docker images should first all be up and running.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "\n",
      "section: Course Management Form for Homeworks\n",
      "question: How to run a dbt-core project as an Airflow Task Group on Google Cloud Composer using a service account JSON key\n",
      "answer: Install the astronomer-cosmos package as a dependency. (see Terraform example).\n",
      "Make a new folder, dbt/, inside the dags/ folder of your Composer GCP bucket and copy paste your dbt-core project there. (see example)\n",
      "Ensure your profiles.yml is configured to authenticate with a service account key. (see BigQuery example)\n",
      "Create a new DAG using the DbtTaskGroup class and a ProfileConfig specifying a profiles_yml_filepath that points to the location of your JSON key file. (see example)\n",
      "Your dbt lineage graph should now appear as tasks inside a task group like this:\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The student is asking about success in Module 1. Since the CONTEXT is currently empty, I need to search the FAQ database for information related to Module 1, success tips, and what's required for it.\", \"keywords\": [\"Module 1 success tips\", \"how to succeed in Module 1\", \"Module 1 requirements\", \"Module 1 study guide\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The student is asking for general success tips for Module 1. The current CONTEXT primarily contains solutions to specific technical errors within Module 1 (Docker and Terraform, Python, SQLAlchemy, Psycopg2 issues). While resolving these issues is part of success, the context doesn't provide broader guidance on 'what to do to be successful'. I need to search for more conceptual information about Module 1, such as its objectives, key topics, or learning outcomes, which can indirectly inform the student on how to succeed.\", \"keywords\": [\"Module 1 learning outcomes\", \"Module 1 core topics\", \"Module 1 objectives\", \"Module 1 important skills\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"The student is asking for advice on how to be successful in Module 1. The current CONTEXT provides solutions to specific technical issues encountered in Module 1 (related to Docker, Terraform, Python, and PostgreSQL/SQLAlchemy). While resolving these issues is part of success, the context does not offer a broader overview, learning objectives, or general success tips for the module. My previous broad searches for 'success tips', 'requirements', 'study guide', 'learning outcomes', 'core topics', and 'objectives' did not yield this type of general guidance from the FAQ. Therefore, I need to try one more targeted search to find an overview or description of Module 1's content to provide a more comprehensive answer. 'Module 1 overview' is a good candidate for this purpose.\",\n",
      "  \"keywords\": [\n",
      "    \"Module 1 overview\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #3...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 3. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "Module 1 study guide\n",
      "Module 1 requirements\n",
      "Module 1 important skills\n",
      "Module 1 overview\n",
      "how to succeed in Module 1\n",
      "Module 1 learning outcomes\n",
      "Module 1 core topics\n",
      "Module 1 success tips\n",
      "Module 1 objectives\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Module “kafka” not found when trying to run producer.py\n",
      "answer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\n",
      "To create a virtual env and install packages (run only once)\n",
      "python -m venv env\n",
      "source env/bin/activate\n",
      "pip install -r ../requirements.txt\n",
      "To activate it (you'll need to run it every time you need the virtual env):\n",
      "source env/bin/activate\n",
      "To deactivate it:\n",
      "deactivate\n",
      "This works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\n",
      "Also the virtual environment should be created only to run the python file. Docker images should first all be up and running.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "\n",
      "section: Course Management Form for Homeworks\n",
      "question: How to run a dbt-core project as an Airflow Task Group on Google Cloud Composer using a service account JSON key\n",
      "answer: Install the astronomer-cosmos package as a dependency. (see Terraform example).\n",
      "Make a new folder, dbt/, inside the dags/ folder of your Composer GCP bucket and copy paste your dbt-core project there. (see example)\n",
      "Ensure your profiles.yml is configured to authenticate with a service account key. (see BigQuery example)\n",
      "Create a new DAG using the DbtTaskGroup class and a ProfileConfig specifying a profiles_yml_filepath that points to the location of your JSON key file. (see example)\n",
      "Your dbt lineage graph should now appear as tasks inside a task group like this:\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The student is asking about success in Module 1. Since the CONTEXT is currently empty, I need to search the FAQ database for information related to Module 1, success tips, and what's required for it.\", \"keywords\": [\"Module 1 success tips\", \"how to succeed in Module 1\", \"Module 1 requirements\", \"Module 1 study guide\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The student is asking for general success tips for Module 1. The current CONTEXT primarily contains solutions to specific technical errors within Module 1 (Docker and Terraform, Python, SQLAlchemy, Psycopg2 issues). While resolving these issues is part of success, the context doesn't provide broader guidance on 'what to do to be successful'. I need to search for more conceptual information about Module 1, such as its objectives, key topics, or learning outcomes, which can indirectly inform the student on how to succeed.\", \"keywords\": [\"Module 1 learning outcomes\", \"Module 1 core topics\", \"Module 1 objectives\", \"Module 1 important skills\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The student is asking for advice on how to be successful in Module 1. The current CONTEXT provides solutions to specific technical issues encountered in Module 1 (related to Docker, Terraform, Python, and PostgreSQL/SQLAlchemy). While resolving these issues is part of success, the context does not offer a broader overview, learning objectives, or general success tips for the module. My previous broad searches for 'success tips', 'requirements', 'study guide', 'learning outcomes', 'core topics', and 'objectives' did not yield this type of general guidance from the FAQ. Therefore, I need to try one more targeted search to find an overview or description of Module 1's content to provide a more comprehensive answer. 'Module 1 overview' is a good candidate for this purpose.\", \"keywords\": [\"Module 1 overview\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER\",\n",
      "  \"answer\": \"To be successful in Module 1, which focuses on Docker and Terraform, based on the provided FAQ, you should be aware of and prepared to troubleshoot common technical issues related to setting up your environment. The FAQ highlights several specific problems and their solutions:\\n\\n1.  **Postgres/psycopg2 issues**: You might encounter `ModuleNotFoundError: No module named 'psycopg2'` when working with Postgres. The solution often involves installing or upgrading `psycopg2-binary` (e.g., `pip install psycopg2-binary` or `pip install psycopg2-binary --upgrade`). If using Conda, updating it and reinstalling might be necessary. On a Mac, `brew install postgresql` could be required if `pg_config` is not found.\\n2.  **SQLAlchemy errors**: When connecting to a PostgreSQL database using SQLAlchemy, you might face a `TypeError: 'module' object is not callable` if your connection string is not correctly formatted. Ensure you use the `postgresql+psycopg://` dialect for your connection string, for example: `conn_string = \\\"postgresql+psycopg://root:root@localhost:5432/ny_taxi\\\"`.\\n\\nBeyond these specific technical points, to generally succeed in Module 1 and similar technical modules, I recommend the following:\\n\\n*   **Understand the Core Concepts**: Focus on grasping the fundamental principles of Docker (containers, images, Dockerfiles, Docker Compose) and Terraform (Infrastructure as Code, providers, resources, state management). Don't just copy-paste code; understand *why* you are doing what you are doing.\\n*   **Hands-on Practice**: Actively work through all the provided labs and assignments. The best way to learn these tools is by using them.\\n*   **Troubleshooting Skills**: Be prepared to debug issues. When you encounter errors, read the error messages carefully, search for solutions (as demonstrated by the FAQ entries), and try to understand the root cause.\\n*   **Review Lectures and Materials**: Go through the lecture videos and any supplementary materials multiple times if necessary. Pause and re-watch complex sections.\\n*   **Ask Questions**: If you're stuck after attempting to troubleshoot, don't hesitate to ask questions in the course forum or to your TAs. Explaining your problem can often help you identify the solution, and getting help quickly can prevent frustration.\\n*   **Time Management**: Allocate sufficient time for studying and completing assignments, especially given the hands-on nature of the module.\\n\\nBy being proactive with your learning and prepared for common technical hurdles, you'll be well-positioned for success in Module 1.\",\n",
      "  \"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"what do I need to do to be successful at module 1?\"\n",
    "\n",
    "search_queries = []\n",
    "search_results = []\n",
    "previous_actions = []\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "while True:\n",
    "    print(f'ITERATION #{iteration}...')\n",
    "\n",
    "    context = build_context(search_results)\n",
    "    prompt = prompt_template.format(\n",
    "        question=question,\n",
    "        context=context,\n",
    "        search_queries=\"\\n\".join(search_queries),\n",
    "        previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "        max_iterations=3,\n",
    "        iteration_number=iteration\n",
    "    )\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(json.dumps(answer, indent=2))\n",
    "\n",
    "    previous_actions.append(answer)\n",
    "\n",
    "    action = answer['action']\n",
    "    if action != 'SEARCH':\n",
    "        break\n",
    "\n",
    "    keywords = answer['keywords']\n",
    "    search_queries = list(set(search_queries) | set(keywords))\n",
    "    \n",
    "    for k in keywords:\n",
    "        res = search(k)\n",
    "        search_results.extend(res)\n",
    "\n",
    "    search_results = dedup(search_results)\n",
    "    \n",
    "    iteration = iteration + 1\n",
    "    if iteration >= 4:\n",
    "        break\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "47d41418-6290-4867-9347-0bd5f86a51dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': 'To be successful in Module 1, which focuses on Docker and Terraform, based on the provided FAQ, you should be aware of and prepared to troubleshoot common technical issues related to setting up your environment. The FAQ highlights several specific problems and their solutions:\\n\\n1.  **Postgres/psycopg2 issues**: You might encounter `ModuleNotFoundError: No module named \\'psycopg2\\'` when working with Postgres. The solution often involves installing or upgrading `psycopg2-binary` (e.g., `pip install psycopg2-binary` or `pip install psycopg2-binary --upgrade`). If using Conda, updating it and reinstalling might be necessary. On a Mac, `brew install postgresql` could be required if `pg_config` is not found.\\n2.  **SQLAlchemy errors**: When connecting to a PostgreSQL database using SQLAlchemy, you might face a `TypeError: \\'module\\' object is not callable` if your connection string is not correctly formatted. Ensure you use the `postgresql+psycopg://` dialect for your connection string, for example: `conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"`.\\n\\nBeyond these specific technical points, to generally succeed in Module 1 and similar technical modules, I recommend the following:\\n\\n*   **Understand the Core Concepts**: Focus on grasping the fundamental principles of Docker (containers, images, Dockerfiles, Docker Compose) and Terraform (Infrastructure as Code, providers, resources, state management). Don\\'t just copy-paste code; understand *why* you are doing what you are doing.\\n*   **Hands-on Practice**: Actively work through all the provided labs and assignments. The best way to learn these tools is by using them.\\n*   **Troubleshooting Skills**: Be prepared to debug issues. When you encounter errors, read the error messages carefully, search for solutions (as demonstrated by the FAQ entries), and try to understand the root cause.\\n*   **Review Lectures and Materials**: Go through the lecture videos and any supplementary materials multiple times if necessary. Pause and re-watch complex sections.\\n*   **Ask Questions**: If you\\'re stuck after attempting to troubleshoot, don\\'t hesitate to ask questions in the course forum or to your TAs. Explaining your problem can often help you identify the solution, and getting help quickly can prevent frustration.\\n*   **Time Management**: Allocate sufficient time for studying and completing assignments, especially given the hands-on nature of the module.\\n\\nBy being proactive with your learning and prepared for common technical hurdles, you\\'ll be well-positioned for success in Module 1.',\n",
       " 'source': 'OWN_KNOWLEDGE'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0fc3a7bc-ee48-4888-9652-7f9a09dfedd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fb5d73-0425-4f8b-98dd-113e88345aa6",
   "metadata": {},
   "source": [
    "## Function calling (\"tool use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c6aab03e-f653-4e82-9362-ddfba53ce286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aa30ef3a-99e6-4e50-94ef-9d76a7431bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"search\",\n",
    "    \"description\": \"Search the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query text to look up in the course FAQ.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "de560ff4-7a38-4734-abe2-5149459eb873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_call(tool_call_response):\n",
    "    function_name = tool_call_response.name\n",
    "    arguments = json.loads(tool_call_response.arguments)\n",
    "\n",
    "    f = globals()[function_name]\n",
    "    result = f(**arguments)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"function_call_output\",\n",
    "        \"call_id\": tool_call_response.call_id,\n",
    "        \"output\": json.dumps(result, indent=2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ddeb26b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.176.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from google-generativeai) (4.25.8)\n",
      "Requirement already satisfied: pydantic in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from google-generativeai) (2.8.2)\n",
      "Requirement already satisfied: tqdm in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from google-generativeai) (4.12.2)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.6.15)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages (from pydantic->google-generativeai) (2.20.1)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading google_api_python_client-2.176.0-py3-none-any.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: uritemplate, protobuf, httplib2, proto-plus, googleapis-common-protos, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "\u001b[2K  Attempting uninstall: protobuf\n",
      "\u001b[2K    Found existing installation: protobuf 4.25.8\n",
      "\u001b[2K    Uninstalling protobuf-4.25.8:\n",
      "\u001b[2K      Successfully uninstalled protobuf-4.25.8\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [google-generativeai]ogle-ai-generativelanguage]\n",
      "\u001b[1A\u001b[2KSuccessfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.25.1 google-api-python-client-2.176.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 googleapis-common-protos-1.70.0 grpcio-status-1.71.2 httplib2-0.22.0 proto-plus-1.26.1 protobuf-5.29.5 uritemplate-4.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a7ba6495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from google.generativeai.types import Tool\n",
    "\n",
    "# 🔑 設定你的 Gemini API 金鑰\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ea2ff680-e6f7-431a-a6f1-7fc6f47f184e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 16\u001b[0m\n\u001b[1;32m      9\u001b[0m tools \u001b[38;5;241m=\u001b[39m [search_tool]\n\u001b[1;32m     11\u001b[0m chat_messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeveloper\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: developer_prompt},\n\u001b[1;32m     13\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: question}\n\u001b[1;32m     14\u001b[0m ]\n\u001b[0;32m---> 16\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mresponses\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     17\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mchat_messages,\n\u001b[1;32m     19\u001b[0m     tools\u001b[38;5;241m=\u001b[39mtools\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m response\u001b[38;5;241m.\u001b[39moutput\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "question = \"How do I do well in module 1?\"\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "If you look up something in FAQ, convert the student question into multiple queries.\n",
    "\"\"\".strip()\n",
    "\n",
    "tools = [search_tool]\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")\n",
    "response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9018a341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/horus/anaconda3/envs/llm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'FunctionResponse' from 'google.generativeai.types' (/home/horus/anaconda3/envs/llm/lib/python3.9/site-packages/google/generativeai/types/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerativeai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgenai\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerativeai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionResponse\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# ✅ 初始化 Gemini\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'FunctionResponse' from 'google.generativeai.types' (/home/horus/anaconda3/envs/llm/lib/python3.9/site-packages/google/generativeai/types/__init__.py)"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from google.generativeai.types import FunctionResponse\n",
    "\n",
    "import json\n",
    "\n",
    "# ✅ 初始化 Gemini\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "# ✅ 定義 Search Tool（Function Calling 規格）\n",
    "\n",
    "search_tool = [\n",
    "    {\n",
    "        \"function_declarations\": [\n",
    "            {\n",
    "                \"name\": \"search\",\n",
    "                \"description\": \"Search the FAQ database\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Search query text to look up in the course FAQ.\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"query\"]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# ✅ 實作你自己的 search 函式（向量搜尋）\n",
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "    return results\n",
    "\n",
    "# ✅ 包裝成 Gemini 可用的 function_call_output 回傳格式\n",
    "def do_call(tool_call):\n",
    "    function_name = tool_call.name\n",
    "    arguments = dict(tool_call.args)  # ✅ 直接轉為 Python dict\n",
    "\n",
    "    # Call 本地 function\n",
    "    f = globals()[function_name]\n",
    "    result = f(**arguments)\n",
    "\n",
    "    # ✅ 使用 FunctionResponse 格式包裝結果回傳給 Gemini\n",
    "    return FunctionResponse(\n",
    "        name=function_name,\n",
    "        response=json.dumps(result)  # 必須為 JSON string\n",
    "    )\n",
    "\n",
    "# ✅ 啟動聊天模型，支援 tools\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-pro\",\n",
    "    tools=search_tool\n",
    ")\n",
    "\n",
    "\n",
    "# ✅ 使用者輸入\n",
    "question = \"How do I do well in module 1?\"\n",
    "\n",
    "chat = model.start_chat(history=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "            \"You're a course teaching assistant. \"\n",
    "            \"You're given a question from a course student and your task is to answer it. \"\n",
    "            \"If you need to look up something in the FAQ, convert the student question into one or more queries.\"\n",
    "        ]\n",
    "    }\n",
    "])\n",
    "\n",
    "# ✅ 第一步：請 Gemini 判斷是否要用 Tool\n",
    "response = chat.send_message(question)\n",
    "\n",
    "# ✅ 如果 Gemini 要呼叫 Tool（function call），處理它\n",
    "if response.candidates[0].content.parts and hasattr(response.candidates[0].content.parts[0], 'function_call'):\n",
    "    tool_call = response.candidates[0].content.parts[0].function_call\n",
    "    tool_result = do_call(tool_call)\n",
    "\n",
    "    # ✅ 回傳 tool result 給 Gemini 讓它完成任務\n",
    "    response = chat.send_message(tool_result)\n",
    "\n",
    "# ✅ 最終回答\n",
    "print(\"🤖 Gemini 回答：\\n\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4258848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: google-genai\n",
      "Version: 1.25.0\n",
      "Summary: GenAI Python SDK\n",
      "Home-page: https://github.com/googleapis/python-genai\n",
      "Author: \n",
      "Author-email: Google LLC <googleapis-packages@google.com>\n",
      "License: Apache-2.0\n",
      "Location: /home/horus/anaconda3/envs/llm/lib/python3.9/site-packages\n",
      "Requires: anyio, google-auth, httpx, pydantic, requests, tenacity, typing-extensions, websockets\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip show  google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0f2d0c70-621d-453f-a519-35a0fcb37557",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m calls \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241m.\u001b[39moutput\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "calls = response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8776293-78b8-4180-93e0-5c399f8c6fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "for call in calls:\n",
    "    result = do_call(call)\n",
    "    chat_messages.append(call)\n",
    "    chat_messages.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4ce91c-6287-4c7d-bfe9-82edbfc591c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseOutputMessage(id='msg_686401ebe13c81918f6f3c84a1e7cec00e0676c3b7e4712d', content=[ResponseOutputText(annotations=[], text='To do well in Module 1, here are some tips based on common challenges and solutions:\\n\\n1. **Understand Your Environment**:\\n   - Ensure that you have set up your development environment correctly. This includes installing Docker and Terraform as indicated in the module resources.\\n\\n2. **Common Installation Issues**:\\n   - If you encounter errors such as `ModuleNotFoundError: No module named \\'psycopg2\\'`, try installing it via:\\n     ```bash\\n     pip install psycopg2-binary\\n     ```\\n   - If you\\'re still encountering issues, consider updating pip or conda:\\n     ```bash\\n     pip install --upgrade pip\\n     ```\\n     or\\n     ```bash\\n     conda update -n base -c defaults conda\\n     ```\\n\\n3. **PostgreSQL Connectivity**:\\n   - When connecting to PostgreSQL using SQLAlchemy, ensure your connection string is formatted correctly, for example:\\n     ```python\\n     conn_string = \"postgresql+psycopg://username:password@localhost:5432/your_database\"\\n     ```\\n   - If you face errors related to the connection, make sure PostgreSQL is installed and running.\\n\\n4. **Hands-on Practice**:\\n   - Engage in hands-on exercises that utilize Docker and Terraform. The more you practice, the more comfortable you\\'ll be with the concepts.\\n\\n5. **Use Provided Resources**:\\n   - Refer to any supplementary materials provided in the course for additional guidance on technical setups and exercises.\\n\\n6. **Seek Help if Needed**:\\n   - Don’t hesitate to reach out to instructors or peers if you run into any issues. The course community can be a valuable resource.\\n\\nFollowing these tips should enhance your understanding and performance in Module 1! If you have specific topics you\\'d like more detail on, feel free to ask.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")\n",
    "response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f39e2-a611-4ccf-9720-746b6f9202ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in response.output:\n",
    "    chat_messages.append(entry)\n",
    "    print(entry.type)\n",
    "\n",
    "    if entry.type == 'function_call':      \n",
    "        result = do_call(entry)\n",
    "        chat_messages.append(result)\n",
    "    elif entry.type == 'message':\n",
    "        print(entry.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88efef06-cb56-442c-9217-3b12dcc69c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1bf28a-6051-4007-99e7-de18ca996ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "When using FAQ, perform deep topic exploration: make one request to FAQ,\n",
    "and then based on the results, make more requests.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09415738-bfab-4a58-a0ee-99fa25c2f343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " How do I do well in module 1?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function_call: ResponseFunctionToolCall(arguments='{\"query\":\"module 1 tips\"}', call_id='call_IED9lyUZOsS6ToxvZHLNQoN6', name='search', type='function_call', id='fc_686403087180819ebf792db8930e3f830594799b59703b57', status='completed')\n",
      "\n",
      "function_call: ResponseFunctionToolCall(arguments='{\"query\":\"module 1 successful strategies\"}', call_id='call_WAvKTixmfYyoBrF89lS6N46R', name='search', type='function_call', id='fc_68640309279c819ea24ded9b9639c7330594799b59703b57', status='completed')\n",
      "\n",
      "To excel in Module 1, which focuses on Docker and Terraform, here are some key strategies and tips based on common challenges faced by students:\n",
      "\n",
      "1. **Understand Docker Basics**: Start by familiarizing yourself with the Docker ecosystem, including images, containers, and Docker Compose. Having a solid grasp of these concepts will help you avoid common pitfalls.\n",
      "\n",
      "2. **Environment Setup**: Ensure you have a correctly set up local environment. This includes installing Docker and any necessary dependencies. For instance, if you encounter errors like `ModuleNotFoundError: No module named 'psycopg2'`, make sure to install it using:\n",
      "   ```bash\n",
      "   pip install psycopg2-binary\n",
      "   ```\n",
      "   or update as needed if you run into issues.\n",
      "\n",
      "3. **Jupyter Notebooks**: When working in Jupyter notebooks, ensure you can access the necessary libraries. If you run into module errors, consider installing the required packages directly in the notebook, like so:\n",
      "   ```python\n",
      "   !pip install psycopg2-binary\n",
      "   ```\n",
      "\n",
      "4. **Hands-On Practice**: Engage with the hands-on exercises provided in the module. Practicing with real commands and setups will cement your understanding.\n",
      "\n",
      "5. **Ask Questions**: If you're stuck on a particular exercise or concept, don't hesitate to reach out to peers or instructors. Collaborating with others can enhance your learning experience.\n",
      "\n",
      "6. **Review Code and Examples**: Go through the provided examples in the course and try to replicate them. This will give you practical insights into how to apply what you learn.\n",
      "\n",
      "7. **Error Handling**: Learn to read error messages carefully. For instance, if you see errors about missing modules, check your installation commands. Many common issues arise from simple typos or assumptions about package availability.\n",
      "\n",
      "If you keep these strategies in mind and actively engage with the materials, you'll improve your chances of success in Module 1. \n",
      "\n",
      "What specific aspects of Module 1 are you finding challenging?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Docker and Terraform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function_call: ResponseFunctionToolCall(arguments='{\"query\":\"Docker tips for Module 1\"}', call_id='call_zcxJlRqgjfMjavLOgVY1FSj5', name='search', type='function_call', id='fc_6864031f32a0819e850cbe6692b6ab160594799b59703b57', status='completed')\n",
      "\n",
      "function_call: ResponseFunctionToolCall(arguments='{\"query\":\"Terraform tips for Module 1\"}', call_id='call_4n2UHkf4UtPpg3XAM0V5WFfI', name='search', type='function_call', id='fc_6864031f61ec819eba1a01625d5a64430594799b59703b57', status='completed')\n",
      "\n",
      "To do well in Module 1 focusing on Docker and Terraform, here are some targeted tips for both technologies:\n",
      "\n",
      "### Docker Tips:\n",
      "1. **Basic Understanding**: Ensure you have foundational knowledge of Docker, such as how to create and manage containers, and how to use Docker Compose for multi-container applications.\n",
      "\n",
      "2. **Correct Installation**: If you encounter issues like `ModuleNotFoundError: No module named 'psycopg2'`, make sure that you're installing the required Python modules in your Docker environment. Update your Dockerfile to include:\n",
      "   ```Dockerfile\n",
      "   RUN python -m pip install psycopg2-binary\n",
      "   ```\n",
      "\n",
      "3. **Working with Jupyter Notebooks**: When executing code in Jupyter, install necessary modules using:\n",
      "   ```python\n",
      "   !pip install psycopg2-binary\n",
      "   ```\n",
      "\n",
      "4. **Consistent Environment**: Keep your development environment consistent with Docker. Always build and run your containers from the same local environment to minimize errors.\n",
      "\n",
      "### Terraform Tips:\n",
      "1. **Initialization**: When using Terraform, remember to run `terraform init` inside the correct working directory that contains your `.tf` files. If you run it outside, you'll receive errors about missing configurations.\n",
      "\n",
      "2. **Permissions**: Pay attention to permissions in your Google Cloud project. If you encounter a `403` error related to `storage.buckets.create`, ensure you're using the correct Project ID and that the service account has the necessary permissions.\n",
      "\n",
      "3. **Check System Time**: If you face issues with JWT tokens (like `invalid_grant` errors), it might be due to time desynchronization on your machine. Sync your system time using:\n",
      "   ```bash\n",
      "   sudo hwclock -s\n",
      "   ```\n",
      "\n",
      "4. **Error Logging**: When encountering errors, rely on error messages to guide you. For example, if Terraform mentions a state lock issue, review the relevant documentation or GitHub issues related to your error.\n",
      "\n",
      "### General Strategy:\n",
      "- **Practice**: The more you practice using Docker and Terraform, the more comfortable you'll become with their commands and functionalities.\n",
      "  \n",
      "- **Documentation**: Refer to the official Docker and Terraform documentation for troubleshooting and advanced tips. This can be invaluable in resolving specific issues you may face.\n",
      "\n",
      "If you need help with a specific Docker or Terraform command or concept, feel free to ask! What part of Docker or Terraform are you currently struggling with the most?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " stop\n"
     ]
    }
   ],
   "source": [
    "while True: # main Q&A loop\n",
    "    question = input() # How do I do my best for module 1?\n",
    "    if question == 'stop':\n",
    "        break\n",
    "\n",
    "    message = {\"role\": \"user\", \"content\": question}\n",
    "    chat_messages.append(message)\n",
    "\n",
    "    while True: # request-response loop - query API till get a message\n",
    "        response = client.responses.create(\n",
    "            model='gpt-4o-mini',\n",
    "            input=chat_messages,\n",
    "            tools=tools\n",
    "        )\n",
    "\n",
    "        has_messages = False\n",
    "        \n",
    "        for entry in response.output:\n",
    "            chat_messages.append(entry)\n",
    "        \n",
    "            if entry.type == 'function_call':      \n",
    "                print('function_call:', entry)\n",
    "                print()\n",
    "                result = do_call(entry)\n",
    "                chat_messages.append(result)\n",
    "            elif entry.type == 'message':\n",
    "                print(entry.content[0].text)\n",
    "                print()\n",
    "                has_messages = True\n",
    "\n",
    "        if has_messages:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b72e654-8f21-46a9-ac7a-ef67f7bd9120",
   "metadata": {},
   "source": [
    "## Multiple tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af08b204-f01d-4ecf-8232-69ad68c80b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2025-07-01 17:50:28--  https://raw.githubusercontent.com/alexeygrigorev/rag-agents-workshop/refs/heads/main/chat_assistant.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3485 (3.4K) [text/plain]\n",
      "Saving to: 'chat_assistant.py'\n",
      "\n",
      "     0K ...                                                   100%  434K=0.008s\n",
      "\n",
      "2025-07-01 17:50:28 (434 KB/s) - 'chat_assistant.py' saved [3485/3485]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/rag-agents-workshop/refs/heads/main/chat_assistant.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cbac21-c207-4bbd-853e-e5c9dc5329da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entry(question, answer):\n",
    "    doc = {\n",
    "        'question': question,\n",
    "        'text': answer,\n",
    "        'section': 'user added',\n",
    "        'course': 'data-engineering-zoomcamp'\n",
    "    }\n",
    "    index.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ecaa5c-f791-44c1-b09a-86e55caf9eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_entry_description = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"add_entry\",\n",
    "    \"description\": \"Add an entry to the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question to be added to the FAQ database\",\n",
    "            },\n",
    "            \"answer\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The answer to the question\",\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"question\", \"answer\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca7181-427c-49e2-aa09-e486b13760f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'name': 'search',\n",
       "  'description': 'Search the FAQ database',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'query': {'type': 'string',\n",
       "     'description': 'Search query text to look up in the course FAQ.'}},\n",
       "   'required': ['query'],\n",
       "   'additionalProperties': False}}]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chat_assistant\n",
    "\n",
    "tools = chat_assistant.Tools()\n",
    "tools.add_tool(search, search_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0366224-695e-4295-972d-4e6857fdb214",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.add_tool(add_entry, add_entry_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8cdea1-6e33-4fb8-a2ff-d8d59637d28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'name': 'search',\n",
       "  'description': 'Search the FAQ database',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'query': {'type': 'string',\n",
       "     'description': 'Search query text to look up in the course FAQ.'}},\n",
       "   'required': ['query'],\n",
       "   'additionalProperties': False}},\n",
       " {'type': 'function',\n",
       "  'name': 'add_entry',\n",
       "  'description': 'Add an entry to the FAQ database',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'question': {'type': 'string',\n",
       "     'description': 'The question to be added to the FAQ database'},\n",
       "    'answer': {'type': 'string', 'description': 'The answer to the question'}},\n",
       "   'required': ['question', 'answer'],\n",
       "   'additionalProperties': False}}]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78144b8f-0b15-466a-8eca-46ad3d92ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_interface = chat_assistant.ChatInterface()\n",
    "\n",
    "chat = chat_assistant.ChatAssistant(\n",
    "    tools=tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b1ddc-eaa1-4a4c-b591-fe084b9d1eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: How do I do well in module 1?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"do well in module 1\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"query\":\"do well in module 1\"}', call_id='call_4iEnGse7DlYAvMy7ljBlaEDW', name='search', type='function_call', id='fc_6864051e058c81a3b2be4fc97f893c930d66a27d5be27c59', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>[\n",
       "  {\n",
       "    \"text\": \"Issue:\\ne\\u2026\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the \\u201c ModuleNotFoundError: No module named 'psycopg2' \\u201c error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 112\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\n",
       "    \"section\": \"Module 4: analytics engineering with dbt\",\n",
       "    \"question\": \"DBT - Error: No module named 'pytz' while setting up dbt with docker\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 299\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \\\"TypeError: 'module' object is not callable\\\"\\nSolution:\\nconn_string = \\\"postgresql+psycopg://root:root@localhost:5432/ny_taxi\\\"\\nengine = create_engine(conn_string)\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Python - SQLALchemy - TypeError 'module' object is not callable\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 124\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"Error raised during the jupyter notebook\\u2019s cell execution:\\nengine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\\nSolution: Need to install Python module \\u201cpsycopg2\\u201d. Can be installed by Conda or pip.\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 125\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\u201d\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\"` appropriately.\\nAdditionally, you can check for the version of \\u2018py4j\\u2019 of the spark you\\u2019re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\",\n",
       "    \"section\": \"Module 5: pyspark\",\n",
       "    \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 323\n",
       "  }\n",
       "]</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>To excel in Module 1, here are some tips based on the course content:</p>\n",
       "<ol>\n",
       "<li>\n",
       "<p><strong>Understand the Basics</strong>: Ensure you grasp foundational concepts like Docker and Terraform, as these are essential for building a solid understanding in this module.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Practice Regularly</strong>: Engage with the practical assignments and exercises. Working hands-on will reinforce the concepts and tools covered.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Utilize Resources</strong>: Refer to the course materials, documentation, and any suggested readings. These are invaluable for deepening your comprehension.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Ask Questions</strong>: Don’t hesitate to reach out if you encounter difficulties or uncertainties. Engaging with peers or instructors can clarify your understanding.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Review Feedback</strong>: After completing sessions or tasks, take the time to review any feedback provided. This can guide your improvements in subsequent tasks.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Stay Organized</strong>: Keep your work organized, especially when handling multiple tools and configurations so you can easily trace back any errors that may arise.</p>\n",
       "</li>\n",
       "</ol>\n",
       "<p>Would you like more specific advice on any particular aspect of Module 1?</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: add this to the FAQ database\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>add_entry({\"question\":\"How do I do well in module 1?\",\"an...)</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"question\":\"How do I do well in module 1?\",\"answer\":\"1. Understand the Basics: Ensure you grasp foundational concepts like Docker and Terraform.\\\\n2. Practice Regularly: Engage with practical assignments to reinforce concepts.\\\\n3. Utilize Resources: Refer to course materials, documentation, and suggested readings.\\\\n4. Ask Questions: Reach out if you encounter difficulties; engaging with peers or instructors can clarify your understanding.\\\\n5. Review Feedback: Take time to review feedback after completing tasks to guide improvements.\\\\n6. Stay Organized: Keep your work organized to easily trace back errors.\"}', call_id='call_bDeJ7ZqU9rKYPnSSPIgiIvV4', name='add_entry', type='function_call', id='fc_68640534ef8c81a389b44679839c6ce40d66a27d5be27c59', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>null</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>I've added your question and answer to the FAQ database successfully!</p>\n",
       "<p>Do you have any other questions or topics you'd like to explore further?</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "chat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501458d2-2f15-4484-b8f1-f300a5e1f7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How do I do well in module 1?',\n",
       " 'text': '1. Understand the Basics: Ensure you grasp foundational concepts like Docker and Terraform.\\n2. Practice Regularly: Engage with practical assignments to reinforce concepts.\\n3. Utilize Resources: Refer to course materials, documentation, and suggested readings.\\n4. Ask Questions: Reach out if you encounter difficulties; engaging with peers or instructors can clarify your understanding.\\n5. Review Feedback: Take time to review feedback after completing tasks to guide improvements.\\n6. Stay Organized: Keep your work organized to easily trace back errors.',\n",
       " 'section': 'user added',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.docs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d569e-ef87-4afe-839c-f873498d54d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x233d5173b90>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b265a810-7720-4f19-8897-c34fbba4bc55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
